%%----------Chapter 2------------------------------------------
\chapter{Using Yeager to Generate Long Sequence Regression Tests}
The test suite assembled in the previous chapter is a great way for a software development team to verify that the core functionality of the system under test is fundamentally operational. When executed, it will test the few well-understood scenarios we have outlined consistently and, assuming enough assertions are present, thoroughly. In fact, the suite requires the entire process from the previous chapter in order to accommodate the addition of new scenarios.

It's a boring, tedious, and repetitious task that can be the entire career of a test engineer. However, as any test automator will know, tasks which are boring, tedious, and repetitious are ripe targets for computer automation, and the task of scenario authorship is no different.

This chapter will outline a method for adapting the existing test suite explored in the previous chapter, using a tool of our own authorship named Yeager, to enable the computer to generate scenarios automatically. Yeager is an MIT-licensed open source Python 3 module, with source available at \url{https://github.com/elementc/yeager}. It provides a Python annotation and a set of utility functions. Usage of Yeager's state transition annotation allows testers to quickly and easily map an existing suite of test code onto a state machine, in the form of a graph. This graph can then be traversed using the utility functions, thereby generating new test scenarios from the existing code.

The resultant adapted test suite is published online at \url{https://github.com/elementc/monica-tests-yeagerized} for your convenience.

\section{Software as a State Machine}
Consider the system under test, Monica. As a relationship management web site, it has a few obvious states it can be in: logged out and on the landing page, logged in and on the dashboard, viewing a list of contacts, viewing a list of journal entries, or viewing the settings page. This maps nicely to the page objects we defined in the previous chapter. Actions on those page objects assume a current state (e.g., we're logged in and on the dashboard) and after execution are in a new state which may or may not be the same state (eg, the \texttt{Dashboard.click\_contacts\_button()} method transitions from the dashboard to the contacts list, while the \texttt{LoginPage.log\_in\_incorrectly()} method should result in the system being in the same login page it was before the method was run).

In fact, most modern programs can be looked at as systems composed of a finite set of states (pages, in this case) with some state transitions (links) and a data context (the stuff you've already typed into the system in those states). Yeager uses this fact to enable automated test sequence generation.

\subsection{States in Our Example System}
Let's consider Monica's pages, which are already built into our test suite, to be states.

We have: the login page (\texttt{Login}) and logging in takes us to the \texttt{Dashboard} which has tabs for the \texttt{Contacts} list and the \texttt{Journal} log. There's also a \texttt{Settings} page which has subpages for \texttt{Import}, \texttt{Export}, \texttt{Users}, and \texttt{Tags}.

The Dashboard and Contacts list both let us \texttt{AddAContact}, while the Journal tab lets us \texttt{AddAJournalEntry}.

From a given \texttt{Contact}, one can \texttt{AddASignificantOther}, \texttt{AddAChild}, \\\texttt{UpdateJobInformation}, \texttt{AddANote}, \texttt{AddAnActivity}, \texttt{AddAReminder}, \texttt{AddAGift}, and \texttt{AddADebt}.

For the purpose of our discussions, these pages will constitute the entire set of states in the system under test. Conveniently, each of them is a Python class.

\subsection{State Transitions as Actions in Our Example System}
A graph consists of a set of nodes and a set of edges. If our nodes are the states the system under test may be in, the edges are the actions that may be taken from those states, possibly resulting in a state transition. It is certainly possible for an edge to be a loop connecting the starting state to itself. In the particular case of testing web applications, note that though it's reasonable to author a page object model with each method corresponding to an edge, this is not an assumption that is necessary to make, and would-be Yeager adopters may choose to lump lower-level page object methods into clusters of function calls in new functions and treat those higher-level functions as edges instead. In fact, the example Yeagerized Monica tests do just this, creating a suite of Yeager-friendly functions as snippets of existing test sequences, built from page object function calls.

\subsection{Capturing Contextual State}
Before embarking on the journey of high volume test automation that follows, it is important to consider for a moment the entirety of the software system. More than just software, a system includes the entire context of the software's execution, from the software itself, to the contents of the database, to the number of active system threads, to the ambient temperature of the room the system is running in.

Some of these are impossible to control for in a testing environment: it's unreasonable to unseat your CPU cooler to attempt to replicate a bug related to your cousin's dust-clogged Pentium II for instance. Others are possible to configure with initialization scripts and virtualization to a degree, for instance always having the same base OS image and environment variables, or always having the same amount of RAM and number of CPU cores. Still more can be controlled for using database snapshots and well-documented test data. Regardless, remembering these variables, which are external to the code but internal to the system under test, is critical to the development exercises in this chapter.

\subsection{Taking a Walk on the Graph}
Imagine standing on a giant picture of the program under test's state graph, at the starting point. You are able to walk along the lines in the directions they are drawn to new points, but you can't walk backwards against their direction of travel. It's a strange looking environment for sure, many of the nodes you might stand on have leaving edges that just loop back to where they started. Existing test scripts are like following directions along this map, ``from A, go to B, turn right at C, stop at D'' and so on. These pre-planned scripts are an effective way to make sure you visit the whole map at least once.

But, imagine that you had a lot of time to kill and had already done all of your maps for the day. An interesting way to spend your time might be to go wandering: wherever you are, pick one of the paths before you at random and walk that way. Keep flipping coins or rolling n-sided dice and walking and you might eventually trigger a secret passage in the labyrinth you've been wandering. Well, that or crash the program under test. How exciting!

Contrived thought experiments aside, the notion of wandering around a program is a useful one for testing. First, it simulates human usage a little more realistically than many test scenarios (how many users actually start from a freshly booted computer, load up and login to the dashboard, create one record, search for that record, delete that record, then log out?). Second, such a process can be of any arbitrary length which, while also contributing to a more realistic usage simulation\footnote{Consider that the author's instances of the Atom text editor and the GNOME desktop environment have been open on their laptop since August, while the typical Atom CI instance takes 30 minutes to build the software and run all tests.\citep{CircleCI}}, permits test managers to use as much of the technique as they want to- wandering the program under test for a few hours on their laptop during a conference call or over a month on a virtual machine hosted in a cloud somewhere.

\section{Yeager State Transition Annotations}
The meat of Yeager testing is accomplished through the annotation of Python test methods. An \textit{annotation}, also known as a \textit{decorator} or a \textit{function decorator} is a special Python function which is executed at the time of another function's definition, receives the function being defined as well as any other required items as parameters, and can optionally wrap the function being defined in a special modifier. Yeager is implemented as a special Python annotation and a set of utility functions which register after definition and can then call plain old Python functions.

The annotation, \texttt{yeager.state\_transition} and some utility functions \\(\texttt{yeager.add\_state\_to\_blacklist}, \texttt{yeager.orphaned\_states}, \\\texttt{yeager.reachable\_states}, and \texttt{yeager.walk}) are described in this section.

A note on Python convention: there are two kinds of parameters a function may take. The first, \textit{positional arguments}, are passed like this: \texttt{print("some argument")} or \texttt{math.pow(3,2)}. The second, \textit{keyword arguments}, sometimes shortened to \textit{kwargs}, are passed like this:
\\\texttt{timedelta(hours=3, minutes=7, seconds=20)}. Order does not matter with kwargs. Positional arguments and kwargs that aren't explicitly defined in a function's signature can both be captured for use by a function. Positional arguments are captured into a Python \texttt{list} by defining a (potentially semi-) final argument prefixed with a single asterisk, keyword arguments into a Python dictionary (\texttt{dict}) with a final argument prefixed with two asterisks, like this:
\\\texttt{def function(arg1="Default val", *args\_var, **kwargs\_var)}

\subsection{State Identifiers}
Anything that can be a Python \texttt{dict} key can serve as a state identifier. For simplicity's sake we use strings in this document, but as long as Python will allow it, so will Yeager. Enterprising Yeager hackers may use the actual Python page object model class, for instance.

The example implementation of a Yeager test uses unique strings for state identifiers. There's no strong reason for this, it's just illustrative.

\subsection{Basic State Transition Annotations}
The fastest way to get started with using Yeager is to define a function for each of the state transitions you wish to use in the test. These will probably be short snippets from the traditional-style test sequences. Then, for each of these functions, you should use the \texttt{yeager.state\_transition} annotation to mark the transition of that function. Here's an example using some of our Monica test code from the previous chapter:

{\tt
\begin{verbatim}
from pages.login import LoginPage
from pages.dashboard import DashboardPage
from yeager import state_transition

@state_transition(None, "login-page")
def open(driver, **kwargs):
    driver = webdriver.Chrome()
    driver.get("https://app.monicahq.com/")

@state_transition("login-page", "dashboard-page")
def log_in(driver, **kwargs):
    login = LoginPage(driver)
    login.log_in_correctly()

@state_transition("dashboard-page", "login-page")
def log_out(driver, **kwargs):
    dashboard = DashboardPage(driver)
    dashboard.log_out()
\end{verbatim}
}

Note that we use the Python \texttt{None} constant as a reference to the uninitialized system. Yeager treats \texttt{None} as a special node in the implied state model our annotations provide: it's assumed to be the entry point.

\subsection{Verifying Connectedness}
Yeager provides a utility function to check for states which cannot be reached from a given state, probably due to misconfigured annotations. The function, \texttt{yeager.orphaned\_states}, takes one optional argument (the starting state, it defaults to \texttt{None}), and returns a \texttt{list} of all states that Yeager knows about but doesn't know how to get to. The inverse set, the known states, is also provided as a utility function with the same optional argument, as \texttt{yeager.reachable\_states}. Though the orphaned states function is useful for debugging, it can be used in other automated ways, for instance as a test coverage check or a way to automate \texttt{walk} calls with each of the ``orphaned'' states actually being new entry points. They're useful in a number of different contexts for enterprising testers.

\section{Yeager Test Harnesses}
A suite of Yeager-annotated Python functions, while neat, is neither immediately useful (it's still just a chunk of naked functions), nor particularly intrusive (annotating a function with a Yeager state transition only adds a print statement before the function executes). Analysis of the state transition graph can be done manually for sure (\texttt{from yeager import nodes, edges}), but Yeager also provides a set of utility functions to actually exercise the system under test.

\subsection{Test Setup and Entry Point}
It's up to testers to generate Python scripts that start up and execute a Yeager test, but the process is very easy.

The first step is to cause the Python interpreter to parse all of the relevant Yeager annotations. In simple test scripts, it's enough to simply write the test code and annotations at the top of the file, but in large test suites, it may be necessary to import those Python files at the top of the Yeager test script instead. Critically, Yeager annotation metadata exists as long as the Python interpreter instance does, so it doesn't matter what modules or other structure applies to the code the Yeager annotations are spread around in. If it has been parsed, Yeager knows about it.\footnote{Unless modifications have been made to the \texttt{nodes} or \texttt{edges} data structures.}

To actually start taking a walk on the state model, simply call Yeager's \texttt{walk} function.

\subsection{Walk Options and Execution}
The function \texttt{yeager.walk} takes some special arguments that determine how a test will eventually come to an end. If a tester just wants to go walking until they tell it to stop, they can call it with no args and it will run until the test is killed with a \texttt{SIGINT}. If a tester wants to just take a fixed number of steps, they can pass that as a naked integer or kwarg named count to \texttt{walk} and it will run for that many steps and then return. If a tester doesn't care about how long a test runs, and only wants to run until the program gets to some particular state, using the kwarg \texttt{exit\_state} with the desired end state will cause the \texttt{walk} call to return as soon as Yeager wanders to that state. And, finally, if a tester wishes to start the walking from a state other than the default starting state of \texttt{None}, they may do so by supplying the kwarg \texttt{start\_state} with the desired starting state.

All of these different preferences are just plans- the intended way to wander the graph. If an exception is raised in the underlying code, the exception is thrown all the way to the caller. Yeager doesn't try to continue walking since the system under test may be in a corrupt state. It's not possible to resume the existing \texttt{walk}, but it is possible to call \texttt{walk} again from scratch.

\subsection{Application Context}
All other kwargs that are passed to the \texttt{yeager.walk} call will be passed to the transition functions by Yeager, so a driver kwarg could be used to provide a webdriver to a web application's test suite, or a \texttt{dict} named context could store contextual information about the system under test.

Changes to mutable objects are preserved for the rest of execution, so it becomes possible to memoize things like data entered into the system or previously-captured search results. All kwargs unrecognized by the \texttt{walk} call are passed to all of the transition functions that Yeager steps through, so it is in the Yeager test style to have all test functions use the \texttt{**kwargs} catch-all argument in case a new context argument is added in the future of the test suite's development.

\subsection{Logging in Yeager}
Yeager doesn't make any particular assumptions about the logging toolkit that you use. It uses standard output to print its own data, though future revisions might use the standard Python logging interface. For Long Sequence Regression Testing, it is very important to log with vigor, as a failure is often the result of many consecutive steps instead of one instant.

\subsection{Controlling the Path: Blacklists}
While it may seem counterintuitive after going to the effort to define them, it is possible to mark a state as one to not visit during a \texttt{walk}. This is useful, say, in cases where testers might want a run configuration that avoids certain known-buggy regions of the system under test, or try a Yeager test but know parts of their Yeager-specific code is still incomplete. It's accomplished by using the \texttt{yeager.add\_state\_to\_blacklist} function. Any state identifier, when passed as an argument, will not be visited by a Yeager \texttt{walk}.

\subsection{Controlling the Path: Weights}
Humans using software don't truly do actions equally randomly. A user of the Atom text editor, for instance, probably spends more time typing and saving than they do moving tabs around, opening consoles, running compile/lint commands, changing themes or settings, and so on. To enable better simulation of these more-probable actions, Yeager supports the notion of weighting edges.

An edge may be weighted by using a standalone function
\\(\texttt{yeager.set\_edge\_weight}) or by using the weight kwarg with the state transition annotation (\texttt{@state\_transition("st-a", "st-b", weight=10)}). Notionally, an unweighted edge has a weight of 1. This edge gets one entry into the pool of candidates for selection by the \texttt{walk} algorithm. An edge with a weight of 5 gets five entries into the pool. A final edge with a weight of 2 gets two entries into the pool. From the combined pool (with eight entries), one is chosen as a random draw and executed.

\section{Yeager in Action: Torture-Testing Monica}
With the Yeager package described in a general fashion, we now move on to a detailed look at a specific use case: testing the Monica personal CRM. Just as the author provided a reference traditional test suite as the \texttt{monica-tests-traditional} repository, so too have they provided a reference Yeager test suite online at \url{https://github.com/elementc/monica-tests-yeagerized}.

\subsection{Detailed Test Code}

The following test code was used to generate the example runs which follow. It is a snippet of the reference Yeager suite.
%TODO: update with content from the

{\tt
\begin{verbatim}
from selenium import webdriver
from pages.login import LoginPage
from pages.dashboard import DashboardPage
from pages.header_page import HeaderPage
from pages.contacts import ContactsPage
from pages.add_a_contact import AddPersonPage
from pages.contact import ContactPage
from pages.edit_contact import EditContactPage
from yeager import walk
from yeager.annotations import state_transition
driver = None

@state_transition(None, "login-page")
def open(driver):
    driver.get("https://app.monicahq.com/")

@state_transition("login-page", "dashboard-page")
def log_in(driver):
    login = LoginPage(driver)
    login.log_in_correctly()

@state_transition(["dashboard-page", "contacts-page", "journal-page", "settings-page"], "login-page")
def log_out(driver):
    header = HeaderPage(driver)
    header.log_out()

@state_transition(["dashboard-page", "contacts-page", "journal-page", "settings-page"], "dashboard-page")
def dashboard_page(driver):
    header = HeaderPage(driver)
    header.go_dashboard()

@state_transition(["dashboard-page", "contacts-page", "journal-page", "settings-page"], "contacts-page")
def contacts_page(driver):
    header = HeaderPage(driver)
    header.go_contacts()

@state_transition(["dashboard-page", "contacts-page", "journal-page", "settings-page"], "journal-page")
def journal_page(driver):
    header = HeaderPage(driver)
    header.go_journal()

@state_transition(["dashboard-page", "contacts-page", "journal-page", "settings-page"], "settings-page")
def settings_page(driver):
    header = HeaderPage(driver)
    header.go_settings()

@state_transition("contacts-page", "add-contact-page")
def add_someone(driver):
    contacts = ContactsPage(driver)
    contacts.click_add_person()

@state_transition("add-contact-page", "contacts-page")
def cancel_add(driver):
    add = AddPersonPage(driver)
    add.click_cancel_button()

@state_transition("add-contact-page", "contact-page")
def okay_add(driver):
    add = AddPersonPage(driver)
    add.click_add_button()

@state_transition("contact-page", "edit-contact-page")
def edit_contact(driver):
    contact = ContactPage(driver)
    contact.click_edit_contact()

walk(50, driver=webdriver.Chrome())

\end{verbatim}
}

\subsection{Example of Execution: No Bugs}
Running the full code from the above section can yield a number of different outputs. Here's one run which terminates successfully.
{
\begin{verbatim}
executing function <function open at 0x039CB4F8>, current state -> login-page
executing function <function log_in at 0x039CB588>, current state -> dashboard-page
executing function <function log_out at 0x039CB618>, current state -> login-page
executing function <function log_in at 0x039CB588>, current state -> dashboard-page
executing function <function dashboard_page at 0x039CB780>, current state -> dashboard-page
executing function <function dashboard_page at 0x039CB780>, current state -> dashboard-page
executing function <function log_out at 0x039CB618>, current state -> login-page
executing function <function log_in at 0x039CB588>, current state -> dashboard-page
executing function <function settings_page at 0x039CBBB8>, current state -> settings-page
executing function <function contacts_page at 0x039CB8E8>, current state -> contacts-page
executing function <function log_out at 0x039CB618>, current state -> login-page
executing function <function log_in at 0x039CB588>, current state -> dashboard-page
executing function <function journal_page at 0x039CBA50>, current state -> journal-page
executing function <function log_out at 0x039CB618>, current state -> login-page
executing function <function log_in at 0x039CB588>, current state -> dashboard-page
executing function <function log_out at 0x039CB618>, current state -> login-page
executing function <function log_in at 0x039CB588>, current state -> dashboard-page
executing function <function contacts_page at 0x039CB8E8>, current state -> contacts-page
executing function <function add_someone at 0x039CBD20>, current state -> add-contact-page
executing function <function cancel_add at 0x039CBDB0>, current state -> contacts-page
executing function <function settings_page at 0x039CBBB8>, current state -> settings-page
executing function <function contacts_page at 0x039CB8E8>, current state -> contacts-page
executing function <function contacts_page at 0x039CB8E8>, current state -> contacts-page
executing function <function log_out at 0x039CB618>, current state -> login-page
executing function <function log_in at 0x039CB588>, current state -> dashboard-page
executing function <function dashboard_page at 0x039CB780>, current state -> dashboard-page
executing function <function dashboard_page at 0x039CB780>, current state -> dashboard-page
executing function <function journal_page at 0x039CBA50>, current state -> journal-page
executing function <function contacts_page at 0x039CB8E8>, current state -> contacts-page
executing function <function settings_page at 0x039CBBB8>, current state -> settings-page
executing function <function settings_page at 0x039CBBB8>, current state -> settings-page
executing function <function dashboard_page at 0x039CB780>, current state -> dashboard-page
executing function <function log_out at 0x039CB618>, current state -> login-page
executing function <function log_in at 0x039CB588>, current state -> dashboard-page
executing function <function journal_page at 0x039CBA50>, current state -> journal-page
executing function <function settings_page at 0x039CBBB8>, current state -> settings-page
executing function <function contacts_page at 0x039CB8E8>, current state -> contacts-page
executing function <function log_out at 0x039CB618>, current state -> login-page
executing function <function log_in at 0x039CB588>, current state -> dashboard-page
executing function <function journal_page at 0x039CBA50>, current state -> journal-page
executing function <function contacts_page at 0x039CB8E8>, current state -> contacts-page
executing function <function dashboard_page at 0x039CB780>, current state -> dashboard-page
executing function <function contacts_page at 0x039CB8E8>, current state -> contacts-page
executing function <function log_out at 0x039CB618>, current state -> login-page
executing function <function log_in at 0x039CB588>, current state -> dashboard-page
executing function <function dashboard_page at 0x039CB780>, current state -> dashboard-page
executing function <function settings_page at 0x039CBBB8>, current state -> settings-page
executing function <function dashboard_page at 0x039CB780>, current state -> dashboard-page
executing function <function log_out at 0x039CB618>, current state -> login-page
executing function <function log_in at 0x039CB588>, current state -> dashboard-page
\end{verbatim}}

No error message, an exit under our expected conditions (after 50 steps), and a healthy system. Everything looks good!

\subsection{Example of Execution: Bug In Model}
Sometimes, a test fails. Yeager makes no guarantee that a test failure is consistent with a fault in the software. In fact, the only thing it guarantees is that the model doesn't match the software's behavior. This could just as likely represent a fault in the model that Yeager inferred. Here's one such example:

{
\begin{verbatim}
executing function <function open at 0x03539078>, current state -> login-page
executing function <function log_in at 0x03539108>, current state -> dashboard-page
executing function <function contacts_page at 0x03539228>, current state -> contacts-page
executing function <function add_someone at 0x03539420>, current state -> add-contact-page
executing function <function okay_add at 0x035394F8>, current state -> contact-page
executing function <function edit_contact at 0x03539588>, current state -> edit-contact-page
(traceback omitted)
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"link text","selector":"Edit contact information"}
  (Session info: chrome=63.0.3239.59)
  (Driver info: chromedriver=2.32.498550 (9dec58e66c31bcc53a9ce3c7226f0c1c5810906a),platform=Windows NT 10.0.15063 x86_64)
\end{verbatim}
}
Did you catch it? The test begins well enough, then dives into creating a contact. It opens the add-a-contact page, and then directly tries to add the (empty) contact! The next step it takes, trying to open the just-added contact for editing, throws a NoSuchElement exception! Of course, that's because the  ``add this contact'' button didn't actually tansition the system to the contact-page state, instead showing an error message. This is a common failure mode in Yeager tests, and unfotunately it doesn't represent a bug in the software so much as a bug in the test code: there's an implicit requirement that the add-contact-page state must have something unique put into the name fields before the add button will work as expected. This can be mitigated by using a separate pseudo-state (``add-contact-page'' and ``add-contact-page-filled'') through the use of an on-transition callback, or through runtime manipulation of the Yeager blacklist.

\subsection{Example of Execution: Bug In Software}
Haven't found one yet... few candidates. Will be filled.

\subsection{Inferred Monica State Graph}

Here's a visualization of what Yeager infers as the System Under Test's state model. Interestingly, it may be the case that the development of Yeager tests helps to better document or at least helps testers to better understand the structure of the system under test by providing such a concise model.

% INSERT GRAPHIC FROM graph_tool Here

% INSERT CODE USED TO GENERATE IT HERE
